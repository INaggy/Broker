**University Data Management System**
A comprehensive, polyglot persistence system for managing university data with real-time synchronization across multiple databases using Kafka Connect, featuring a microservices architecture with API Gateway.

ğŸ—ï¸ **System Architecture**
This project implements a robust microservices architecture:

**Core Components**
â€¢ **API Gateway** (gateway/) - JWT authentication and request routing

â€¢ **Lab1 Service** - Attendance reporting with Elasticsearch integration

â€¢ **Lab2 Service** - Audience reporting with Neo4j analytics

â€¢ **Lab3 Service** - Group reporting with Redis caching

**Database Ecosystem**
â€¢ PostgreSQL - Primary transactional database with partitioned attendance data

â€¢ MongoDB - Document storage for hierarchical university structure

â€¢ Neo4j - Graph database for relationship analysis

â€¢ Redis - High-performance cache and search index for students

â€¢ Elasticsearch - Full-text search engine for lecture materials

â€¢ Kafka Connect - Real-time data synchronization between systems

ğŸ“Š **Data Model**
**PostgreSQL Schema**
â€¢ University â†’ Institute â†’ Department â†’ Specialty â†’ Group â†’ Students

â€¢ Course_of_lecture â†’ Lecture â†’ Material_of_lecture

â€¢ Schedule with automated semester partitioning

â€¢ Attendance with dynamic table partitioning by semester

ğŸš€ **Quick Start**
**Prerequisites**

Docker and Docker Compose
Python 3.8+

**Installation**
1.Clone the repository

```
git clone <https://github.com/INaggy/Project-with-Kafka-connect>
cd Project-with-Kafka-connect
```

2.Start all services

```docker-compose up -d```

3.Initialize the database schema

```python postgres.py```

4.Generate sample data

```python attendance_generator.py```

5.Synchronize data to all systems

```python total_generator.py```

6.Configure Kafka Connect connectors
```
# Debezium PostgreSQL connector
curl -X POST -H "Content-Type: application/json" --data @debezium.json http://localhost:8083/connectors

# Elasticsearch sink connector
curl -X POST -H "Content-Type: application/json" --data @elastic_sink.json http://localhost:8083/connectors

# Neo4j sink connector  
curl -X POST -H "Content-Type: application/json" --data @neo4j_sink.json http://localhost:8083/connectors

# Redis sink connector
curl -X POST -H "Content-Type: application/json" --data @redis_sink.json http://localhost:8083/connectors
```
7.Start the microservices
```
# Each service runs in its own container via docker-compose
docker-compose up gateway lab1 lab2 lab3
```
ğŸ”Œ **API Endpoints**
**Authentication**
```
curl -X POST http://localhost:1337/auth/login \
  -H "Content-Type: application/json" \
  -d '{"username": "user", "password": "user"}'
```
**Lab1 - Attendance Report**
```
curl -X POST http://localhost:1337/api/lab1/report \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer <JWT_TOKEN>" \
  -d '{"term": "physics", "start_date": "2025-09-01", "end_date": "2025-12-31"}'
```
**Lab2 - Audience Report**
```
curl -X POST http://localhost:1337/api/lab2/audience_report \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer <JWT_TOKEN>" \
  -d '{"year": 2025, "semester": 1}'
```
**Lab3 - Group Report**
```
curl -X POST http://localhost:1337/api/lab3/group_report \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer <JWT_TOKEN>" \
  -d '{"group_id": 1}'
```
ğŸ”§ **Kafka Connect Configuration**
The project includes four main connectors:

**1. Debezium PostgreSQL Connector**
â€¢ Monitors PostgreSQL changes via logical replication

â€¢ Captures CDC (Change Data Capture) events

â€¢ Publishes to Kafka topics with table names

**2. Elasticsearch Sink Connector**
â€¢ Syncs lecture materials to Elasticsearch

â€¢ Enables full-text search capabilities

â€¢ Maintains document versioning

**3. Neo4j Sink Connector**
â€¢ Creates graph nodes and relationships in Neo4j

â€¢ Handles complex relationship mappings

â€¢ Uses APOC procedures for advanced operations

**4. Redis Sink Connector**
â€¢ Stores student data in Redis for fast access

â€¢ Creates hash structures for student records

â€¢ Enables quick student lookup and search

ğŸ“ **Project Structure**

Project-with-Kafka-connect/
â”œâ”€â”€ gateway/                 # API Gateway service
â”‚   â”œâ”€â”€ gateway.py          # Main gateway application
â”‚   â”œâ”€â”€ requirements.txt    # Python dependencies
â”‚   â””â”€â”€ Dockerfile          # Container configuration
â”œâ”€â”€ lab1_service/           # Attendance reporting service
â”‚   â”œâ”€â”€ app.py             # Flask application
â”‚   â”œâ”€â”€ Lab1.py            # Business logic
â”‚   â”œâ”€â”€ requirements.txt   # Dependencies
â”‚   â””â”€â”€ Dockerfile         # Container config
â”œâ”€â”€ lab2_service/           # Audience analytics service
â”‚   â”œâ”€â”€ app.py             # Flask app
â”‚   â”œâ”€â”€ Lab2.py            # Business logic
â”‚   â”œâ”€â”€ neo4j_sync.py      # Neo4j synchronization
â”‚   â”œâ”€â”€ requirements.txt   # Dependencies
â”‚   â””â”€â”€ Dockerfile         # Container config
â”œâ”€â”€ lab3_service/           # Group reporting service
â”‚   â”œâ”€â”€ app.py             # Flask app
â”‚   â”œâ”€â”€ Lab33.py           # Business logic
â”‚   â”œâ”€â”€ neo4j_sync.py      # Neo4j operations
â”‚   â”œâ”€â”€ redis_module.py    # Redis utilities
â”‚   â”œâ”€â”€ requirements.txt   # Dependencies
â”‚   â””â”€â”€ Dockerfile         # Container config
â”œâ”€â”€ data/                   # Configuration and data files
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ data_config.json
â”‚   â”œâ”€â”€ debezium.json      # PostgreSQL CDC connector
â”‚   â”œâ”€â”€ elastic_sink.json  # Elasticsearch connector
â”‚   â”œâ”€â”€ neo4j_sink.json    # Neo4j connector
â”‚   â””â”€â”€ redis_sink.json    # Redis connector
â”œâ”€â”€ scripts/                # Data generation and sync scripts
â”‚   â”œâ”€â”€ postgres.py        # Database schema setup
â”‚   â”œâ”€â”€ attendance_generator.py # Sample data generation
â”‚   â”œâ”€â”€ total_generator.py # Full synchronization
â”‚   â”œâ”€â”€ mongo_sync.py      # MongoDB synchronization
â”‚   â”œâ”€â”€ neo4j_sync.py      # Neo4j synchronization
â”‚   â”œâ”€â”€ redis_sync.py      # Redis synchronization
â”‚   â”œâ”€â”€ elastic_gen_sync.py # Elasticsearch sync
â”‚   â”œâ”€â”€ elastic_output.py  # Elasticsearch utilities
â”‚   â””â”€â”€ ClearDB_data.py    # Database cleanup
â”œâ”€â”€ docker-compose.yml      # Multi-container setup
â””â”€â”€ README.md

ğŸ¯ **Sample Data**
The system includes comprehensive sample data for Russian universities:

â€¢ 28 Universities - Major Russian educational institutions

â€¢ 29 Institutes - Various academic departments

â€¢ 28 Departments - Specialized academic units

â€¢ 28 Specialties - Academic disciplines and fields

â€¢ 28 Student Groups - Organized student cohorts

â€¢ 10 Courses - Academic course offerings

â€¢ 10 Lectures - Individual lecture sessions

â€¢ 10 Materials - Educational resources and materials

ğŸ”§ **Configuration**
**Environment Variables**

Gateway Service:

â€¢ JWT_SECRET_KEY - Secret for JWT token signing

â€¢ LAB1_URL - URL to Lab1 service (default: http://lab1:5001)

â€¢ LAB2_URL - URL to Lab2 service (default: http://lab2:5002)

â€¢ LAB3_URL - URL to Lab3 service (default: http://lab3:5003)

Database Connections:

â€¢ PostgreSQL: localhost:5430 (external), postgres:5432 (internal)

â€¢ MongoDB: localhost:27017

â€¢ Neo4j: bolt://localhost:7687

â€¢ Redis: localhost:6379

â€¢ Elasticsearch: localhost:9200

ğŸ“Š **Report Types**
**1. Attendance Report (Lab1)**
â€¢ Finds students with worst attendance for specific lectures
â€¢ Combines Elasticsearch search with PostgreSQL attendance data
â€¢ Enriches with Redis student information

**2. Audience Report (Lab2)**
â€¢ Shows course requirements and student counts per lecture
â€¢ Uses Neo4j for relationship traversal
â€¢ Filters by academic year and semester

**3. Group Report (Lab3)**
â€¢ Tracks planned vs actual attendance hours per student
â€¢ Uses PostgreSQL partitioning for performance
â€¢ Redis caching for student data

ğŸ¯ **Usage Examples**
**Search Students**
```
from redis_module import StudentSearch

searcher = StudentSearch()
students = searcher.search_by_name("Ivanov")
students = searcher.search_by_group("CS-101")
```
**Query Lecture Materials**
```
from Lab1 import LectureMaterialSearcher

searcher = LectureMaterialSearcher()
results = searcher.search("quantum physics")
```
**Generate Reports**
```
from Lab1 import AttendanceFinder

finder = AttendanceFinder()
report = finder.find_worst_attendees(lecture_ids, top_n=10)
```
ğŸ› **Troubleshooting**
**Common Issues**
1.Connection refused errors
Check all containers are running: docker-compose ps
Verify network connectivity between services
2.Kafka Connect issues
Check connector status: curl http://localhost:8083/connectors
View logs: docker logs kafka-connect
3.Data synchronization problems
Reset databases: python ClearDB_data.py
Repopulate data: python total_generator.py

**Monitoring URLs**
â€¢ Kafka UI: http://localhost:8082

â€¢ Control Center: http://localhost:9021

â€¢ Neo4j Browser: http://localhost:7474 (neo4j/strongpassword)

â€¢ Elasticsearch: http://localhost:9200 (elastic/secret)

â€¢ Kafka Connect: http://localhost:8083

ğŸ”® **Future Enhancements**
â€¢Real-time attendance monitoring dashboard
â€¢Machine learning for student performance prediction
â€¢Mobile application interface
â€¢Advanced graph analytics
â€¢API rate limiting and monitoring
â€¢Automated testing suite
â€¢Enhanced security features
â€¢Performance optimization

ğŸ“ **License**
This project is for educational purposes. Ensure proper licensing for production use.

ğŸ“§ **Support**
For questions and support, please open an issue in the GitHub repository.

