**University Data Management System**
A comprehensive, polyglot persistence system for managing university data with real-time synchronization across multiple databases using Kafka Connect, featuring a microservices architecture with API Gateway.

üèóÔ∏è **System Architecture**
This project implements a robust microservices architecture:

**Core Components**
‚Ä¢ **API Gateway** (gateway/) - JWT authentication and request routing

‚Ä¢ **Lab1 Service** - Attendance reporting with Elasticsearch integration

‚Ä¢ **Lab2 Service** - Audience reporting with Neo4j analytics

‚Ä¢ **Lab3 Service** - Group reporting with Redis caching

**Database Ecosystem**
‚Ä¢ PostgreSQL - Primary transactional database with partitioned attendance data

‚Ä¢ MongoDB - Document storage for hierarchical university structure

‚Ä¢ Neo4j - Graph database for relationship analysis

‚Ä¢ Redis - High-performance cache and search index for students

‚Ä¢ Elasticsearch - Full-text search engine for lecture materials

‚Ä¢ Kafka Connect - Real-time data synchronization between systems

üìä **Data Model**
**PostgreSQL Schema**
‚Ä¢ University ‚Üí Institute ‚Üí Department ‚Üí Specialty ‚Üí Group ‚Üí Students

‚Ä¢ Course_of_lecture ‚Üí Lecture ‚Üí Material_of_lecture

‚Ä¢ Schedule with automated semester partitioning

‚Ä¢ Attendance with dynamic table partitioning by semester

üöÄ **Quick Start**
**Prerequisites**

Docker and Docker Compose
Python 3.8+

**Installation**
1.Clone the repository

```
git clone <https://github.com/INaggy/Project-with-Kafka-connect>
cd Project-with-Kafka-connect
```

2.Start all services

```docker-compose up -d```

3.Initialize the database schema

```python postgres.py```

4.Generate sample data

```python attendance_generator.py```

5.Synchronize data to all systems

```python total_generator.py```

6.Configure Kafka Connect connectors
```
# Debezium PostgreSQL connector
curl -X POST -H "Content-Type: application/json" --data @debezium.json http://localhost:8083/connectors

# Elasticsearch sink connector
curl -X POST -H "Content-Type: application/json" --data @elastic_sink.json http://localhost:8083/connectors

# Neo4j sink connector  
curl -X POST -H "Content-Type: application/json" --data @neo4j_sink.json http://localhost:8083/connectors

# Redis sink connector
curl -X POST -H "Content-Type: application/json" --data @redis_sink.json http://localhost:8083/connectors
```
7.Start the microservices
```
# Each service runs in its own container via docker-compose
docker-compose up gateway lab1 lab2 lab3
```
üîå **API Endpoints**
**Authentication**
```
curl -X POST http://localhost:1337/auth/login \
  -H "Content-Type: application/json" \
  -d '{"username": "user", "password": "user"}'
```
**Lab1 - Attendance Report**
```
curl -X POST http://localhost:1337/api/lab1/report \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer <JWT_TOKEN>" \
  -d '{"term": "physics", "start_date": "2025-09-01", "end_date": "2025-12-31"}'
```
**Lab2 - Audience Report**
```
curl -X POST http://localhost:1337/api/lab2/audience_report \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer <JWT_TOKEN>" \
  -d '{"year": 2025, "semester": 1}'
```
**Lab3 - Group Report**
```
curl -X POST http://localhost:1337/api/lab3/group_report \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer <JWT_TOKEN>" \
  -d '{"group_id": 1}'
```
üîß **Kafka Connect Configuration**
The project includes four main connectors:

**1. Debezium PostgreSQL Connector**
‚Ä¢ Monitors PostgreSQL changes via logical replication

‚Ä¢ Captures CDC (Change Data Capture) events

‚Ä¢ Publishes to Kafka topics with table names

**2. Elasticsearch Sink Connector**
‚Ä¢ Syncs lecture materials to Elasticsearch

‚Ä¢ Enables full-text search capabilities

‚Ä¢ Maintains document versioning

**3. Neo4j Sink Connector**
‚Ä¢ Creates graph nodes and relationships in Neo4j

‚Ä¢ Handles complex relationship mappings

‚Ä¢ Uses APOC procedures for advanced operations

**4. Redis Sink Connector**
‚Ä¢ Stores student data in Redis for fast access

‚Ä¢ Creates hash structures for student records

‚Ä¢ Enables quick student lookup and search

üéØ **Sample Data**
The system includes comprehensive sample data for Russian universities:

‚Ä¢ 28 Universities - Major Russian educational institutions

‚Ä¢ 29 Institutes - Various academic departments

‚Ä¢ 28 Departments - Specialized academic units

‚Ä¢ 28 Specialties - Academic disciplines and fields

‚Ä¢ 28 Student Groups - Organized student cohorts

‚Ä¢ 10 Courses - Academic course offerings

‚Ä¢ 10 Lectures - Individual lecture sessions

‚Ä¢ 10 Materials - Educational resources and materials

üîß **Configuration**
**Environment Variables**

Gateway Service:

‚Ä¢ JWT_SECRET_KEY - Secret for JWT token signing

‚Ä¢ LAB1_URL - URL to Lab1 service (default: http://lab1:5001)

‚Ä¢ LAB2_URL - URL to Lab2 service (default: http://lab2:5002)

‚Ä¢ LAB3_URL - URL to Lab3 service (default: http://lab3:5003)

Database Connections:

‚Ä¢ PostgreSQL: localhost:5430 (external), postgres:5432 (internal)

‚Ä¢ MongoDB: localhost:27017

‚Ä¢ Neo4j: bolt://localhost:7687

‚Ä¢ Redis: localhost:6379

‚Ä¢ Elasticsearch: localhost:9200

üìä **Report Types**
**1. Attendance Report (Lab1)**
‚Ä¢ Finds students with worst attendance for specific lectures
‚Ä¢ Combines Elasticsearch search with PostgreSQL attendance data
‚Ä¢ Enriches with Redis student information

**2. Audience Report (Lab2)**
‚Ä¢ Shows course requirements and student counts per lecture
‚Ä¢ Uses Neo4j for relationship traversal
‚Ä¢ Filters by academic year and semester

**3. Group Report (Lab3)**
‚Ä¢ Tracks planned vs actual attendance hours per student
‚Ä¢ Uses PostgreSQL partitioning for performance
‚Ä¢ Redis caching for student data

üéØ **Usage Examples**
**Search Students**
```
from redis_module import StudentSearch

searcher = StudentSearch()
students = searcher.search_by_name("Ivanov")
students = searcher.search_by_group("CS-101")
```
**Query Lecture Materials**
```
from Lab1 import LectureMaterialSearcher

searcher = LectureMaterialSearcher()
results = searcher.search("quantum physics")
```
**Generate Reports**
```
from Lab1 import AttendanceFinder

finder = AttendanceFinder()
report = finder.find_worst_attendees(lecture_ids, top_n=10)
```
üêõ **Troubleshooting**
**Common Issues**
1.Connection refused errors
Check all containers are running: docker-compose ps
Verify network connectivity between services
2.Kafka Connect issues
Check connector status: curl http://localhost:8083/connectors
View logs: docker logs kafka-connect
3.Data synchronization problems
Reset databases: python ClearDB_data.py
Repopulate data: python total_generator.py

**Monitoring URLs**
‚Ä¢ Kafka UI: http://localhost:8082

‚Ä¢ Control Center: http://localhost:9021

‚Ä¢ Neo4j Browser: http://localhost:7474 (neo4j/strongpassword)

‚Ä¢ Elasticsearch: http://localhost:9200 (elastic/secret)

‚Ä¢ Kafka Connect: http://localhost:8083

üîÆ **Future Enhancements**
‚Ä¢Real-time attendance monitoring dashboard
‚Ä¢Machine learning for student performance prediction
‚Ä¢Mobile application interface
‚Ä¢Advanced graph analytics
‚Ä¢API rate limiting and monitoring
‚Ä¢Automated testing suite
‚Ä¢Enhanced security features
‚Ä¢Performance optimization

üìù **License**
This project is for educational purposes. Ensure proper licensing for production use.

üìß **Support**
For questions and support, please open an issue in the GitHub repository.

